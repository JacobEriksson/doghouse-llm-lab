# Section 3

## Agents for life! ğŸ¢âœ¨

Remember how the execs were all about â€œno agentsâ€ last week? Well, apparently someone gave them a very convincing PowerPoint, and now theyâ€™ve done a complete 180. Turns out, adding an agent is the new â€œmust-haveâ€ because, according to the latest wisdom, it will unlock even more â€œvaluable dataâ€â€”their words, not mine.

So, you know what that means: itâ€™s time to switch gears and add that agent we werenâ€™t supposed to need!

Hereâ€™s what weâ€™re fixing up:

- Deploy the Tracing agent â€“ The execs are convinced itâ€™s going to give us all kinds of glorious insights into our appâ€™s performance and AI magic. Letâ€™s get it installed and plugged in so they can start seeing those â€œvaluableâ€ metrics theyâ€™re after.

- Supercharge Observability â€“ Now that weâ€™re agent-enabled, we can get way more detailed data. Performance metrics? Traces? Weird spikes at 3 a.m. because the chatbot decided to overthink a customerâ€™s request for a blue doghouse? Weâ€™re going to know everything. Itâ€™s basically our new superpower.

- Impress the Execs â€“ Letâ€™s be real: the goal here is to make the dashboards so shiny that the execs think weâ€™ve somehow unlocked the secrets of the universe. If the dataâ€™s looking good and the appâ€™s running smooth, weâ€™re golden.

So, itâ€™s time to embrace the agent life, plug it all in, and letâ€™s make sure that chatbotâ€”and the rest of the systemâ€”is performing like a rock star. And who knows? Maybe this agent really will give us some next-level insights. ğŸš€

## Exercise

1. Add the dd-agent to docker-compose.yaml to run it in parallel to the webapp, remember to add or edit necessary environment variables.
2. Remove the agentless environment variable. 
3. Rebuild your images and compose files and run it. 
4. Generate some traffic using the webapp and Chatbot.
5. Regroup with the wider team and discuss the differences. 

## Useful documentation

**Links**
- [LLM Observability Quickstart](https://docs.datadoghq.com/llm_observability/quickstart/?site=us)
- [Tutorial - Enabling Tracing for a Python Application and Datadog Agent in Containers](https://docs.datadoghq.com/tracing/guide/tutorial-enable-python-containers/)


**Docker commands** 
```
# Build your Docker Compose file
docker-compose -f docker-compose.yaml build web_app

# Launch your containers
docker-compose up web_app datadog -d
```

PS. Remember variables KEY="VALUE" docker-compose up web_app -d 

## Help

### 1. Adding the Agent to run parallel to the application
In previous section, we leveraged the agentless version of LLM Obs that gives us limited visibility in to our application. By adding the Datadog Agent, we can also start collecting additional data such as Infrastructure metrics, processes, Logs, APM and more. This also enables us to manually trace the LLM application to provide more granular insights, but more on that later.

The way to do this, we will have to update the docker-compose.yaml file and add the necessary config:

```
services:
  datadog:
    container_name: dd-agent
    image: "gcr.io/datadoghq/agent:latest"
    environment:
      - DD_APM_NON_LOCAL_TRAFFIC=true
      - DD_DOGSTATSD_NON_LOCAL_TRAFFIC="true" 
      - DD_HOSTNAME=datadog
      - DD_APM_ENABLED=true
      - DD_API_KEY=<DD_API_KEY> # Your Datadog Sandbox API Key
      # - DD_SITE=<DD_SITE> # Specify the Datadog Site where your Sandbox Environment resides

    volumes:
      - /proc/:/host/proc/:ro
      - /sys/fs/cgroup/:/host/sys/fs/cgroup:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
  web_app:
   ...
     ..
```

### 2. No more agentless
Now when we are running the application with an agent, we can remove the environment variable on the web_app that instruct the application to leverage the agent instead.

Remove the following line in your docker-compose.yaml:
```
DD_LLMOBS_AGENTLESS_ENABLED=1
```

Now launch your application:
```
docker-compose up web_app datadog -d
```