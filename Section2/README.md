# Section 2

## Oohh, we need better support.. With AI..

It wasn't just observability we needed apparently. Customers are complaining about our support, so the execs decided that we should implement a support bot using OpenAI.. 

Yea I know.. We are getting fired soon, enjoy it while you can.. 

PS.. We need to observe the OpenAI usage and cost, can you make sure it works with Datadog as well?

####Here's the actions:
1. Create an OpenAI API KEY
2. Add additional app.routes and chat functionality in app.py
3. Create the chatbot.html and add a link in base.html page
4. Add OpenAI Env variables to docker-compose file
4. Build and test the chatbot!

####Add the observability:
Hmm.. I'm not really sure, I didn't have time to look in to it.. I think we should be able to use the OpenAI Quickstart with LLMOMBS Agentless.. 

Check the following documentation [LLM Observability Quickstart](https://docs.datadoghq.com/llm_observability/quickstart/?site=us)
Makes sense?

## How-to

text