# Section 2

## Oohh, we need better customer support.. With AI..

It wasn't just observability we needed apparently. Customers are complaining about our support, so the execs decided that we should implement a support bot using OpenAI.. 

Yea I know.. We are getting fired soon, enjoy it while you can.. 

PS.. We need to observe the OpenAI usage and cost, can you make sure it works with Datadog as well?

#### Here's the actions:
1. Create an OpenAI API KEY
2. Add additional app.routes and chat functionality in app.py
3. Create the chatbot.html and add a link in base.html page
4. Add OpenAI Env variables to docker-compose file
4. Build and test the chatbot!

#### Add the observability:
Hmm.. I'm not really sure, I didn't have time to look in to it.. I think we should be able to use the OpenAI Quickstart with LLMOMBS Agentless.. 

Check the following documentation [LLM Observability Quickstart](https://docs.datadoghq.com/llm_observability/quickstart/?site=us)


Did you manage to get it to work? 
(Topics to discuss with your collague)
- What can we see in Datadog? Dashboards, traces, metrics, LLMs?
- LLM Observability, what can we see? Anything missing?


## How-to

text